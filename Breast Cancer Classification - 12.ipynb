{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f35277ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w1/d0vz58wn4g97cyt63qhc_44w0000gn/T/ipykernel_12065/1693390048.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# For tensorflow related imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import torch\n",
    "import numpy as np \n",
    "import time # For meassuring running time of the training.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# ResNet Model and it's supporting functions\n",
    "from ResNET import Block, ResNET\n",
    "from helper_functions import to_categorical, calculate_accuracy, prepare_data_for_resnet\n",
    "\n",
    "\n",
    "# For tensorflow related imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# For inception\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Disabling all the warnings in the final version\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bb4fd7",
   "metadata": {},
   "source": [
    "## ResNet Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a2423c",
   "metadata": {},
   "source": [
    "#### Generating data for ResNET:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef3465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_path = \"./data/\"\n",
    "dataset_path = \"./data/\"#base_path + \"/dataset/\"\n",
    "\n",
    "path = './data/**/*.png'\n",
    "\n",
    "data_size = 5\n",
    "batch_size = 2\n",
    "target_size = (224,224)\n",
    "\n",
    "train_loader, valid_loader, test_loader = prepare_data_for_resnet(path, data_size, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b46b6",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d178038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurations\n",
    "\n",
    "num_epochs = 1\n",
    "lr = 0.001\n",
    "batch_size = 128\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_classes = 2\n",
    "img_channel = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a47a50",
   "metadata": {},
   "source": [
    "__Assert block__ to check if the implemented Model class return the correct label dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a484f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    resnet = ResNET(Block, [3, 4, 6, 3], img_channel, num_classes)\n",
    "    _x = torch.randn(2, 3, 244, 244)\n",
    "    _y = resnet(_x).to(device)\n",
    "    return (_y.shape)\n",
    "assert test() == (2,2), “Y is wrong shape!”\n",
    "print(“Correct!“)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db778baa",
   "metadata": {},
   "source": [
    "#### Initializing the ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730965d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNET Layers [3, 4, 6, 3] for 34 and 50\n",
    "model = ResNET(Block, [3, 4, 6, 3], img_channel, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5aa0c",
   "metadata": {},
   "source": [
    "#### Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c35812",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "minibatch_loss_list, train_acc_list, valid_acc_list = [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model = model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "      \n",
    "        features = torch.tensor(features, dtype=torch.float32)\n",
    "        features = torch.transpose(features, 3, 1)#(x, 1, 3)\n",
    "        targets = torch.tensor(targets, dtype=torch.float32)\n",
    "      \n",
    "        logits = model(features)\n",
    "        cost = loss(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "      \n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n",
    "                    %(epoch+1, num_epochs, batch_idx, \n",
    "                      len(train_loader), cost))\n",
    "          \n",
    "    model = model.eval() # eval mode to prevent upd. batchnorm params during inference\n",
    "    with torch.set_grad_enabled(False):# save memory during inference\n",
    "        train_acc, train_pred = calculate_accuracy(model, train_loader)\n",
    "        valid_acc, valid_pred = calculate_accuracy(model, valid_loader)\n",
    "        print('Epoch: %03d/%03d training accuracy: %.2f%% | Validation accuracy: %.2f%%' % (\n",
    "              epoch+1, num_epochs, \n",
    "              train_acc, valid_acc))\n",
    "        train_acc_list.append(train_acc.item())\n",
    "        valid_acc_list.append(valid_acc.item())\n",
    "\n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "\n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0159241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model for future use\n",
    "#torch.save(model.state_dict(), 'resNET_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ae9798",
   "metadata": {},
   "source": [
    "#### Display the accuracy Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c71dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = len(train_acc_list)\n",
    "\n",
    "plt.plot(np.arange(1, num_epochs+1),\n",
    "          train_acc_list, label='Training')\n",
    "plt.plot(np.arange(1, num_epochs+1),\n",
    "          valid_acc_list, label='Validation')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db56dd5f",
   "metadata": {},
   "source": [
    "#### Computing test accuracy and plotting a few examples with their predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8511d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, predictions = calculate_accuracy(model, test_loader)\n",
    "print('Test accuracy: %.2f%%' % (acc))\n",
    "\n",
    "#%% Training data visualization\n",
    "images, labels = next(iter(test_loader))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "for i in range(9):\n",
    "    \n",
    "    plt.subplot(3, 3, i+1)\n",
    "    label = np.argmax( labels[i+10] ,axis=0)\n",
    "    \n",
    "    ## Debugging\n",
    "    #print(len(label))\n",
    "    #print(predictions.shape)\n",
    "    #print(images[i].shape, ' : ', images[i].permute(1, 2, 0).shape)\n",
    "    #print(predictions[i].item(), '|', label.item())\n",
    "    \n",
    "    str = F\"P: {predictions[i+10].item()},\\nL: {label.item()}\"\n",
    "    plt.title(str)\n",
    "    plt.imshow(images[i+10])\n",
    "    \n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c2dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_predictions_and_labels(data_loader, device = 'cpu'):\n",
    "    \n",
    "    labels = None\n",
    "    logits = None\n",
    "    \n",
    "    for batch_idx, (features, targets) in enumerate(data_loader):\n",
    "        features = torch.tensor(features, dtype=torch.float32)\n",
    "        features = torch.transpose(features, 3, 1)#(x, 1, 3)\n",
    "        targets = torch.tensor(targets, dtype=torch.float32)\n",
    "        \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        logits = model(features)\n",
    "        labels = targets\n",
    "    \n",
    "    labels = np.argmax( labels ,axis=1)\n",
    "    logits = np.argmax( logits.detach().numpy() ,axis=1)\n",
    "    \n",
    "    return labels, logits\n",
    "\n",
    "def get_classification_matrics(data_loader, target_names = ['0', '1'], device = 'cpu'):\n",
    "    labels, prediction = get_predictions_and_labels(data_loader, device)\n",
    "    \n",
    "    print(classification_report(labels, prediction, target_names=target_names))\n",
    "    \n",
    "    print_confusion_matrix(labels, prediction, \n",
    "                           title = 'Confusion Matrix of ResNET',\n",
    "                           x_lable = 'Predicted Label',\n",
    "                           y_lable = 'True Label')\n",
    "    \n",
    "def print_confusion_matrix(labels, prediction, title, x_lable, y_lable, fig_size = 5):\n",
    "    \n",
    "    resNet_cm = confusion_matrix(labels, prediction)\n",
    "    f,ax = plt.subplots(figsize=(fig_size, fig_size))\n",
    "    sns.heatmap(resNet_cm, annot=True, linewidths=0.01,cmap=\"OrRd\",linecolor=\"black\", fmt= '.1f',ax=ax)\n",
    "    plt.xlabel(y_lable)\n",
    "    plt.ylabel(x_lable)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "get_classification_matrics(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01acf051",
   "metadata": {},
   "source": [
    "### Importing Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af06b07e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697e3aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = listdir(base_path)\n",
    "#len(folder)\n",
    "\n",
    "total_images = 0\n",
    "for n in range(len(folder)):\n",
    "    patient_id = folder[n]\n",
    "    for c in [0, 1]:\n",
    "        patient_path = base_path + patient_id \n",
    "        class_path = patient_path + \"/\" + str(c) + \"/\"\n",
    "        subfiles = listdir(class_path)\n",
    "        total_images += len(subfiles)\n",
    "        \n",
    "#total_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6340341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b2e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(index=np.arange(0, total_images), columns=[\"patient_id\", \"path\", \"target\"])\n",
    "\n",
    "k = 0\n",
    "for n in range(len(folder)):\n",
    "    patient_id = folder[n]\n",
    "    patient_path = base_path + patient_id \n",
    "    for c in [0,1]:\n",
    "        class_path = patient_path + \"/\" + str(c) + \"/\"\n",
    "        subfiles = listdir(class_path)\n",
    "        for m in range(len(subfiles)):\n",
    "            image_path = subfiles[m]\n",
    "            data.iloc[k][\"path\"] = class_path + image_path\n",
    "            data.iloc[k][\"target\"] = c\n",
    "            data.iloc[k][\"patient_id\"] = patient_id\n",
    "            k += 1  \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98bfa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14842b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_cancer_data = data.query(\"target == 0\").head(data_size)\n",
    "print(non_cancer_data['target'].value_counts())\n",
    "cancer_data = data.query(\"target == 1\").head(data_size)\n",
    "print(cancer_data['target'].value_counts())\n",
    "sliced_data = pd.concat([non_cancer_data,cancer_data])\n",
    "print(sliced_data['target'].value_counts())\n",
    "\n",
    "print(sliced_data['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd63f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_data.target.unique()\n",
    "\n",
    "sliced_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5ef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_data.head()\n",
    "sliced_data.loc[:, \"target\"] = data.target.astype(np.str)\n",
    "sliced_data.info()\n",
    "\n",
    "unique_paths = sliced_data.path.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c3afc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d795377",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_ids, test_ids = train_test_split(unique_paths,\n",
    "                                           test_size=0.2,\n",
    "                                           random_state=0)\n",
    "train_ids, valid_ids = train_test_split(sub_train_ids, test_size=0.1, random_state=0)\n",
    "\n",
    "print(f\"Now, we're taking {round(len(train_ids)/unique_paths.shape[0]*100, 1)}% for training, \n",
    "      {round(len(valid_ids)/unique_paths.shape[0]*100,1)}% for validation, \n",
    "      {round(len(test_ids)/unique_paths.shape[0]*100,1)}% for testing\")\n",
    "\n",
    "print(f'{len(train_ids)}, {len(valid_ids)}, {len(test_ids)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7804d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = sliced_data.loc[sliced_data.path.isin(train_ids),:].copy()\n",
    "test_df = sliced_data.loc[sliced_data.path.isin(test_ids),:].copy()\n",
    "valid_df = sliced_data.loc[sliced_data.path.isin(valid_ids),:].copy()\n",
    "\n",
    "print(f\"train set shape: {train_df.shape}\")\n",
    "print(f\"test set shape: {test_df.shape}\")\n",
    "print(f\"validation set shape: {valid_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be483336",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "valid_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b910958",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 40, \n",
    "                                   width_shift_range = 0.2, \n",
    "                                   height_shift_range = 0.2, \n",
    "                                   shear_range = 0.2, \n",
    "                                   zoom_range = 0.2, \n",
    "                                   horizontal_flip = True, \n",
    "                                   vertical_flip =True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4950ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col = 'path', \n",
    "    y_col ='target',\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "valid_batches = valid_datagen.flow_from_dataframe(\n",
    "    valid_df,\n",
    "    x_col = 'path', \n",
    "    y_col ='target',\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_batches = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col = 'path', \n",
    "    y_col ='target',\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0685aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(20,5))\n",
    "sns.countplot(train_df.target, ax=ax[0], palette=\"Reds\")\n",
    "ax[0].set_title(\"Train data\")\n",
    "sns.countplot(valid_df.target, ax=ax[1], palette=\"Blues\")\n",
    "ax[1].set_title(\"Valid data\")\n",
    "sns.countplot(test_df.target, ax=ax[2], palette=\"Greens\");\n",
    "ax[2].set_title(\"Test data\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a788332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a9f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0748f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionV3(base_model,save_model_path):\n",
    "    \"\"\"Explanation:\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    base_model :\n",
    "    tf.keras.applications.InceptionV3\n",
    "    --------\n",
    "    save_model_path : containing the path where to save the model.\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    InceptionV3_model: keras.engine.functional.Functional\n",
    "    -------------\n",
    "    \"\"\" \n",
    "    \"\"\" Creating Model \"\"\"\n",
    "\n",
    "    base_model = base_model\n",
    "    \n",
    "    # Freezing Layers  \n",
    "    \"\"\"..Freezing the layers and making it non-training except the last three layers..\"\"\"\n",
    "    for layer in base_model.layers[:-3]:\n",
    "        \n",
    "        layer.trainable=False \n",
    "\n",
    "    \"\"\" ...Building Inception Model....\"\"\"\n",
    "    InceptionV3_model=Sequential() # Making it sequential \n",
    "    InceptionV3_model.add(base_model) # Adding the base_model to the sequencial model\n",
    "\n",
    "    \"\"\"Adding the Droupout and Flatten Layers\"\"\"\n",
    "    InceptionV3_model.add(Dropout(0.5))\n",
    "    InceptionV3_model.add(Flatten())\n",
    "\n",
    "    \"\"\"Adding Dense layer and sigmoid function\"\"\"\n",
    "    InceptionV3_model.add(Dense(1,activation='sigmoid',name='output'))\n",
    "\n",
    "    return InceptionV3_model\n",
    "\n",
    "\"\"\"Call this function to create inceptionV3 model...\"\"\"        \n",
    "InceptionV3_model = InceptionV3(base_model=tf.keras.applications.InceptionV3(input_shape=(224,224,3),\n",
    "                                                                             include_top=False,\n",
    "                                                                             weights=\"imagenet\"),\n",
    "                                save_model_path=\"./test/\")\n",
    "\n",
    "InceptionV3_model.summary() # Summary of the created model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f4312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d4e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d137ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(InceptionV3_model,train_batches, valid_batches, epochs):\n",
    "    \"\"\"Explanation:\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    InceptionV3_model :\n",
    "    \n",
    "    containing implemented model\n",
    "    \n",
    "    --------\n",
    "    \n",
    "    train_batches :\n",
    "    containing the training for training the inceptionV3 model.\n",
    "\n",
    "    ---------\n",
    "    \n",
    "    valid_batches :\n",
    "    containing the validation set required for observing the hyperparameters of the inceptionV3 model.\n",
    "    \n",
    "    ---------\n",
    "    epochs : number of epochs needed for training\n",
    "    \n",
    "    Returns : N/A\n",
    "    -------------\n",
    "    \"\"\" \n",
    "    \n",
    "    \"\"\" Crompiling the Model \"\"\"\n",
    "    \n",
    "    InceptionV3_model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate= 0.0001), metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    \"\"\" Checkpoints for monitoring validation accuracy by which it helps the model to save when there is no improvement. \"\"\"\"\n",
    "    \n",
    "    model_checkpoints = tf.keras.callbacks.ModelCheckpoint(\"Breast_Cancer_InceptionV3_model.weights.best.h5\", save_best_only=True, verbose = 1,  mode='max',  monitor='val_accuracy')\n",
    "    \n",
    "    \"\"\"\" It helps the model to save from under and over fitting. It saves the model there is no improvement anymore to save the model from overfitting.\"\"\"\n",
    "    early_stopping = keras.callbacks.EarlyStopping( monitor=\"val_accuracy\", mode=\"max\",patience=5,verbose=1)\n",
    "    \n",
    "    # Regarding Early Stop and Model Checkpoints as Calssbacks\n",
    "    callbacks = [model_checkpoints,early_stopping]\n",
    "    \n",
    "    \"\"\"Saving the history of the model..\"\"\"\n",
    "    inception_history = InceptionV3_model.fit(train_batches, validation_data = valid_batches, epochs = num_epochs, callbacks = [callbacks], verbose = 1)\n",
    "    \n",
    "training_loop(InceptionV3_model,train_batches, valid_batches, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331deaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loading the already trained model...\"\"\"\n",
    "def load_InceptionV3(loaded_model):\n",
    "    model=load_model(loaded_model)\n",
    "    return model\n",
    "loaded_InceptionV3 = load_InceptionV3(\"inceptionv3_mode.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec1ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test_inceptionV3(test_batches):\n",
    "    inception_model_loss, inception_model_accuracy = InceptionV3_model.evaluate(test_batches, verbose=2)\n",
    "    print(\"Restored model, accuracy: {:5.2f}%\".format(100 * inception_model_accuracy))\n",
    "    print(\"Restored model, loss: {:5.2f}%\".format(100 * inception_model_loss))\n",
    "    \n",
    "print_test(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fd465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss\n",
    "plt.plot(inception_history.history['loss'], label='Train Loss')\n",
    "plt.plot(inception_history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(\"InceptionV3 Model Loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215379b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracies\n",
    "plt.plot(inception_history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(inception_history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(\"InceptionV3 Model Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58085ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores() :\n",
    "    \n",
    "    \"\"\"Doining prediction for each classes.\"\"\"\n",
    "    \n",
    "    Y_pred_inception = InceptionV3_model.predict_generator(test_batches, test_df.shape[0] // batch_size+1)\n",
    "    y_pred_inception = np.where(Y_pred_inception > 0.5, 1, 0).flatten()\n",
    "    \n",
    "    \"\"\"Doining prediction for each classes.\"\"\"\n",
    "    \n",
    "    inception_cm = confusion_matrix(test_batches.classes, y_pred_inception)\n",
    "    f,ax = plt.subplots(figsize=(8, 8))\n",
    "    sns.heatmap(inception_cm, annot=True, linewidths=0.01,cmap=\"Purples\",linecolor=\"black\", fmt= '.1f',ax=ax)\n",
    "    \n",
    "    \"\"\"Plotting confusion matrix title.\"\"\"\n",
    "    \n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix of InceptionV3\")\n",
    "    plt.show()\n",
    "    \n",
    "    \"\"\"Plotting score values : Precision, Recall, f1-score\"\"\"\n",
    "    \n",
    "    print(classification_report(test_batches.classes, y_pred_inception, target_names=['0', '1']))\n",
    "    \n",
    "scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b106a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9751d0c",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33db2e61",
   "metadata": {},
   "source": [
    "### Model Creation\n",
    "\n",
    "The following functions will be useful to create a VGG16 model. The function  `create_vgg16_model` will create/load a VGG16 model.\n",
    "\n",
    "\n",
    "**Run the code cell below** to create a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d3fd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# VGG16\n",
    "vgg16_model_path = \"VGG16_model.h5\"\n",
    "vgg16_model_plot_path = \"vgg16_model.png\"\n",
    "vgg16_model_history_path = \"vgg16_history.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f79f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vgg16_model(model_path=None):\n",
    "    \"\"\"breif description.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    model_path : String\n",
    "      String containing the path of a model.\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    vgg_model: keras.engine.functional.Functional\n",
    "      Model containing .... \n",
    "    \"\"\"\n",
    "    if model_path:\n",
    "        return tf.keras.models.load_model(model_path)\n",
    "    else:\n",
    "        \"\"\" Load VGG model with imagenet trained weights and pass our input shape . \"\"\"\n",
    "        base_model = tf.keras.applications.vgg16.VGG16(\n",
    "            weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "            input_shape=(224, 224, 3),\n",
    "        )\n",
    "        \n",
    "        \"\"\" Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights. \"\"\"\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        \"\"\" Add all layers to model except the output layer. \"\"\"\n",
    "        new_model = keras.models.Sequential()\n",
    "        new_model._name=\"VGG16\"\n",
    "        \n",
    "        for layer in base_model.layers[0:-1]:\n",
    "            new_model.add(layer)\n",
    "            \n",
    "        \"\"\" Add all layers to model except the output layer. \"\"\"\n",
    "        new_model.add(layers.Dense(1, activation=\"sigmoid\", name='output'))\n",
    "        \n",
    "        return new_model\n",
    "        \n",
    "vgg_model = create_vgg16_model(vgg16_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5d947e",
   "metadata": {},
   "source": [
    "### Model Summary\n",
    "\n",
    "**Run the code cell below** to create a summary of our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe00c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(vgg_model))\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbc8609",
   "metadata": {},
   "source": [
    "### Model Plotting\n",
    "**Run the code cell below** to create a plot of a model and download it. \n",
    "\n",
    "*Make sure you have installed `pydot` & `graphviz` for plot_model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9393fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(vgg_model, to_file=vgg16_model_plot_path, show_shapes=True, dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3dab95",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "**Compile the model with necessary configs:**\n",
    "\n",
    "* Here I will be using **Adam** optimiser to reach to the global minima while training out model. If I am stuck in local minima while training then the adam optimiser will help us to get out of local minima and reach global minima. We will also specify the **learning rate** of the optimiser, here in this case it is set at **0.001**. If our training is bouncing a lot on epochs then we need to decrease the learning rate so that we can reach global minima.\n",
    "\n",
    "* **binary_crossentropy** function computes the cross-entropy loss between true labels and predicted labels.\n",
    "\n",
    "* And metrics will be **accuracy**.\n",
    "\n",
    "\n",
    "***If you don't want to train the model, you can skip this cell.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31be0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate= 0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb40130d",
   "metadata": {},
   "source": [
    "**Train the model with callbacks function:**\n",
    "\n",
    "* **ModelCheckpoint** - It helps us to save the model by monitoring a specific parameter of the model. In this case I am monitoring validation accuracy by passing `val_accuracy` to ModelCheckpoint. The model will only be saved to disk if the validation accuracy of the model in current epoch is greater than what it was in the last epoch.\n",
    "\n",
    "* **EarlyStopping** - It helps us to stop the training of the model early if there is no increase in the parameter which I have set to monitor in EarlyStopping. In this case I am monitoring validation accuracy by passing `val_accuracy` to EarlyStopping. I have here set patience to `5` which means that the model will stop to train if it doesn’t see any rise in validation accuracy in 5 epochs.\n",
    "\n",
    "\n",
    "***If you don't want to train the model, you can skip this cell.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feef03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoints = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"Breast_Cancer_VGG16_model.weights.best.h5\", \n",
    "    save_best_only=True, \n",
    "    verbose=1, \n",
    "    mode='max', \n",
    "    monitor='val_accuracy'\n",
    ")\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    patience=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    model_checkpoints,\n",
    "    early_stopping\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4ec2f6",
   "metadata": {},
   "source": [
    "**Model fitting**\n",
    "\n",
    "Here, I will pass training and validation data, `epochs` is set to 100, `callbacks` and `verbose` is 2. \n",
    "\n",
    "***If you don't want to train the model, you can skip this cell.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0cafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_history = vgg_model.fit(\n",
    "    train_batches, \n",
    "    validation_data=valid_batches, \n",
    "    epochs = num_epochs,\n",
    "    callbacks=callbacks, \n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6755569",
   "metadata": {},
   "source": [
    "**Store training history**\n",
    "\n",
    "***If you don't want to train the model, you can skip this cell.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4447de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(vgg16_model_history_path, 'w') as file:\n",
    "    json.dump(vgg_history.history, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3f9aba",
   "metadata": {},
   "source": [
    "**Retrive training history**\n",
    "\n",
    "Loading history from a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ddf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(vgg16_model_history_path) as file:\n",
    "    vgg_history_data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb17e1dc",
   "metadata": {},
   "source": [
    "**Plot the training and validation outcome**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73d3257",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vgg_history_data[\"accuracy\"])\n",
    "plt.plot(vgg_history_data['val_accuracy'])\n",
    "plt.plot(vgg_history_data['loss'])\n",
    "plt.plot(vgg_history_data['val_loss'])\n",
    "plt.title(\"VGG16 model's training and validation outcome\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\", \"Loss\", \"Validation Loss\"])\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db3fc33",
   "metadata": {},
   "source": [
    "**Save model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f39104",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.save(vgg16_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa4aec8",
   "metadata": {},
   "source": [
    "### Evalutaion\n",
    "\n",
    "Evaluate model on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model_loss, vgg_model_accuracy = vgg_model.evaluate(test_batches, verbose=2)\n",
    "print(\"Accuracy: {:5.2f}%\".format(100 * vgg_model_accuracy))\n",
    "print(\"Loss: {:5.2f}%\".format(100 * vgg_model_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665142f5",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "It visualizes and summarizes the performance of a classification algorithm.\n",
    "\n",
    "*0 -> Non-IDC*\n",
    "\n",
    "*1 -> IDC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2dbd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_vgg = vgg_model.predict_generator(test_batches, test_df.shape[0] // batch_size+1)\n",
    "y_pred_vgg = np.where(Y_pred_vgg >= 0.5, 1, 0).flatten()\n",
    "vgg_cm = confusion_matrix(test_batches.classes, y_pred_vgg)\n",
    "f,ax = plt.subplots(figsize=(4, 4))\n",
    "sns.heatmap(vgg_cm, annot=True, linewidths=0.01, cmap=\"Blues\", linecolor=\"black\", fmt='.1f', ax=ax)\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Actual values\")\n",
    "plt.title(\"Confusion Matrix of VGG16\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a092cd",
   "metadata": {},
   "source": [
    "### Classification Report\n",
    "\n",
    "Here, we will have a performance evaluation metric where we can find **precision**, **recall**, **F1 Score**, and **support** of our trained model.\n",
    "\n",
    "*0 -> Non-IDC*\n",
    "\n",
    "*1 -> IDC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a0c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_batches.classes, y_pred_vgg, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786376c2",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Load one Non-IDC and IDC picture, do prediction on our trained model.\n",
    "\n",
    "*0 -> Non-IDC*\n",
    "\n",
    "*1 -> IDC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d80d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_for_vgg16(dataframe):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    for i, v in enumerate([0, 799]):\n",
    "        plt.subplot(1,2,i+1)\n",
    "        image = cv2.imread(dataframe.loc[v, \"path\"])\n",
    "\n",
    "        # create input data\n",
    "        image_fromarray = Image.fromarray(image, 'RGB')\n",
    "        resize_image = image_fromarray.resize((224, 224))\n",
    "        expand_input = np.expand_dims(resize_image, axis=0)\n",
    "        input_data = np.array(expand_input)\n",
    "        input_data = input_data/255\n",
    "\n",
    "        # prediction\n",
    "        prediction = vgg_model.predict(input_data)\n",
    "\n",
    "        # plot the image\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(image, cmap=plt.cm.binary)\n",
    "        plt.title(\"Actual: %s\" % (\"Non-IDC\" if int(dataframe.loc[v, \"target\"]) == 0 else \"IDC\") )\n",
    "        plt.xlabel(\"Predict: %s\" % (\"IDC\" if prediction >= 0.5 else \"Non-IDC\"))\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "prediction_for_vgg16(test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
